# -*- coding: utf-8 -*-
"""Alexnet Adam

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1coiW03PW5B3z1engdT9Det29ZNQielkf
"""

#Alexnet Model

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import csv
from random import shuffle
import tensorflow as tf
from tqdm import tqdm
import keras,os
from keras.models import Sequential
from keras.layers import Conv2D, Dropout, MaxPooling2D, BatchNormalization, Activation, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

trainDirectory = '/content/drive/MyDrive/Dataset/Train'
testDirectory = "/content/drive/MyDrive/Dataset/Test"
IMG_SIZE = 227
LR = 0.001
MODEL_NAME = 'Sports Image Classification VGG'

def create_label(image_name):
    """ Create an one-hot encoded vector from image name """
    word_label = image_name.split('_')[0]

    if word_label == 'Basketball':
        return np.array([1, 0, 0, 0, 0, 0])
    elif word_label == 'Football':
        return np.array([0, 1, 0, 0, 0, 0])
    elif word_label == 'Rowing':
        return np.array([0, 0, 1, 0, 0, 0])
    elif word_label == 'Swimming':
        return np.array([0, 0, 0, 1, 0, 0])
    elif word_label == 'Tennis':
        return np.array([0, 0, 0, 0, 1, 0])
    elif word_label == 'Yoga':
        return np.array([0, 0, 0, 0, 0, 1])

def create_train_data():
    training_data = []
    labels = []
    for img in tqdm(os.listdir(trainDirectory)):
        path = os.path.join(trainDirectory, img)
        img_data = cv2.imread(path, 1)
        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))
        #img_data = img_data.reshape(IMG_SIZE, IMG_SIZE, 3)
        training_data.append(np.array(img_data))
        labels.append(create_label(img))
    return np.array(training_data), np.array(labels)

x, y = create_train_data()
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)

def Alexnet(){
  # Creating a Sequential model
  model = Sequential()

  # 1st Convolution Layer
  model.add(Conv2D(filters=96, kernel_size=(11,11), input_shape=(227, 227, 3), strides=(4,4), padding='valid'))
  # Normalization
  model.add(BatchNormalization())
  # Activation Function
  model.add(Activation('relu'))
  # Max-Pooling
  model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))

  # 2nd Convolution Layer
  model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))
  # Normalization
  model.add(BatchNormalization())
  # Activation Function
  model.add(Activation('relu'))
  # Max-Pooling
  model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))

  # 3rd Convolution Layer
  model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same'))
  # Normalization
  model.add(BatchNormalization())
  # Activation Function
  model.add(Activation('relu'))

  # 4th Convolution Layer
  model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same'))
  # Normalization
  model.add(BatchNormalization())
  # Activation Function
  model.add(Activation('relu'))

  # 5th Convolution Layer
  model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))
  # Normalization
  model.add(BatchNormalization())
  # Activation Function
  model.add(Activation('relu'))
  # Max-Pooling
  model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))

  # Flattening before passing to the Dense layer
  model.add(Flatten())

  # 1st Dense Layer
  model.add(Dense(4096))
  # Dropout
  model.add(Dropout(0.5))
  # Normalization
  model.add(BatchNormalization())
  # Activation Function
  model.add(Activation('relu'))

  # 2nd Dense Layer
  model.add(Dense(4096))
  # Dropout
  model.add(Dropout(0.5))
  # Normalization
  model.add(BatchNormalization())
  # Activation Function
  model.add(Activation('relu'))

  # Output softmax Layer
  model.add(Dense(6))
  # Activation Function
  model.add(Activation('softmax'))

  model.summary()

  return model
}

from keras.optimizers import Adam
opt = Adam(lr=0.001)
model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

model.fit(X_train, y_train,batch_size= 32,epochs = 50,validation_data = (X_test, y_test), verbose=1)

def create_test_data():
    testing_data=[]
    for img in tqdm(os.listdir(testDirectory)):
        path = os.path.join(testDirectory, img)
        img_data = cv2.imread(path, 1)
        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))
        testing_data.append(np.array(img_data))
    return testing_data

test_data = np.array(create_test_data())
res = model.predict(test_data)

# getting indices of max values
indices = []
for i in res:
  indices.append(np.argmax(i))

images = os.listdir(testDirectory)

images_series = pd.Series(images)

indices_series = pd.Series(indices)

submission_df = pd.DataFrame({'image_name': images_series, 'label': indices_series})

submission_df.to_csv('Alexnet Adam Submission.csv', index=False)

